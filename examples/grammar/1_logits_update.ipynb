{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f4b00e-59c2-4496-a0e5-cd10dff0f0eb",
   "metadata": {},
   "source": [
    "## Changing logits based on desired alliteration\n",
    "\n",
    "We want to generate a poem where as many words as possible start with a desired letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41664a72-3e67-4e57-9e6d-2a01ed7ed8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade --quiet transformers torch fbgemm-gpu accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b078983c-cda3-46d0-8438-d284bc017b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CHANGE this to the Llama model for which you have applied for access via Hugging Face\n",
    "# See: https://www.llama.com/docs/getting-the-models/hugging-face/\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "assert os.environ[\"HF_TOKEN\"][:2] == \"hf\",\\\n",
    "       \"Please sign up for access to the specific Llama model via HuggingFace and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7717ded-01ba-4fa2-b1c4-44b342cc0ab6",
   "metadata": {},
   "source": [
    "## Zero-shot generation\n",
    "\n",
    "Without any logits processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cad70f-b88b-4b35-98fd-d9be4b64f268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ceae09455341fa84b3c2cef59ad01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=MODEL_ID,\n",
    "    use_fast=True,\n",
    "    kwargs={\n",
    "        \"return_full_text\": False,\n",
    "    },\n",
    "    model_kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b573da4-bf5e-4853-b5de-8d7e80fa4337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hee-haw, the donkey sings,\n",
      "A loud voice that joyfully brings,\n",
      "A smile to the heart of a child.\n"
     ]
    }
   ],
   "source": [
    "def generate_poem(animal: str) -> str:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are writing nursery rhymes about animals for a children's book.\n",
    "        Each poem should be 3-5 lines long.\n",
    "        Return only the poem, without any introduction or preamble.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "        Write a poem about a {animal}.\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256)\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "poem = generate_poem(\"donkey\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfecc3-55c7-4059-94bc-eae29d982cab",
   "metadata": {},
   "source": [
    "Result:\n",
    "```\n",
    "Hee-haw, a donkey so bright,\n",
    "Carrying loads with all his might,\n",
    "His soft fur and gentle eyes shine,\n",
    "A friendly friend, always on my mind.\n",
    "```\n",
    "Well shine & mind is not the perfect rhyme,\n",
    "but still pretty good ... but if we ask for the poem about donkeys to\n",
    "also be alliterative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d864a57-d022-4783-884e-dacd778be4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daring donkeys dash down dusty deeds,\n",
      "Doting devotees delighted in their deeds,\n",
      "Doting donkeys deliver delightful dreams,\n",
      "Delighting dreamers daily with their dignified deeds.\n"
     ]
    }
   ],
   "source": [
    "def generate_alliterative_poem(animal: str) -> str:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are writing alliterative nursery rhymes about animals for a children's book.\n",
    "        Each poem should be 3-5 lines long and contain as many words as possible\n",
    "        that start with the desired letter.\n",
    "        Return only the poem, without any introduction or preamble.\n",
    "    \"\"\"\n",
    "    \n",
    "    # alliterate on the first letter of the animal. So, donkey would be D\n",
    "    user_prompt = f\"\"\"\n",
    "        Write a poem about a {animal}. Use many words that start with {animal.upper()[0]}\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256)\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "poem = generate_alliterative_poem(\"donkey\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d68ad3-28df-4a1b-9d77-a4dea150c2a3",
   "metadata": {},
   "source": [
    "Result:\n",
    "```\n",
    "Daring donkeys dash down dusty deeds,\n",
    "Doting devotees delighted in their deeds,\n",
    "Doting donkeys deliver delightful dreams,\n",
    "Delighting dreamers daily with their dignified deeds.\n",
    "```\n",
    "The poem above is not great. By trying to match the style, the quality has gone way down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d262c-edd8-40e7-8441-9cfc8f8dd1f7",
   "metadata": {},
   "source": [
    "## Use logits processing to enhance the alliteration\n",
    "\n",
    "We'll use the poem prompt, but use logits processing to prefer words that start with the desired letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef0ee7d-e7f9-4354-b511-958d53a7ecf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Little donkey, ears so bright,\n",
      "Hee-hawing loud through day's delight,\n",
      "He trots along with gentle pace,\n",
      "A friendly friend in a sunny place.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers.generation.logits_process import (\n",
    "    LogitsProcessor,\n",
    "    LOGITS_PROCESSOR_INPUTS_DOCSTRING,\n",
    ")\n",
    "from transformers.utils import add_start_docstrings\n",
    "\n",
    "class AlliterativeLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, tokenizer, start_letter):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.start_letter = start_letter\n",
    "      \n",
    "    @add_start_docstrings(LOGITS_PROCESSOR_INPUTS_DOCSTRING)\n",
    "    def __call__(\n",
    "        self, input_ids: torch.LongTensor, input_logits: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        output_logits = input_logits.clone()\n",
    "            \n",
    "        num_matches = [0] * len(input_ids)\n",
    "        for idx, seq in enumerate(input_ids):\n",
    "            # decode the sequence\n",
    "            decoded = self.tokenizer.decode(seq)\n",
    "            # count the number of words that start with desired letter\n",
    "            num_matches[idx] = np.sum([1 for word in decoded.split() if word[0] == self.start_letter])\n",
    "        max_matches = np.max(num_matches)\n",
    "          \n",
    "        # logits goes from -inf to zero.  Mask out the non-max sequences; torch doesn't like it to be -np.inf\n",
    "        for idx in range(len(input_ids)):\n",
    "            if num_matches[idx] != max_matches:\n",
    "                output_logits[idx] = -10000\n",
    "                  \n",
    "        return output_logits\n",
    "    \n",
    "def generate_alliterative_poem_v2(animal: str) -> str:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are writing nursery rhymes about animals for a children's book.\n",
    "        Each poem should be 3-5 lines long.\n",
    "        Return only the poem, without any introduction or preamble.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "        Write a poem about a {animal}.\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    # alliterate on the first letter of the animal. So, donkey would be D\n",
    "    grammar_processor = AlliterativeLogitsProcessor(pipe.tokenizer, animal[0])\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256,\n",
    "                   do_sample=True,\n",
    "                   temperature=0.8,\n",
    "                   num_beams=10,\n",
    "                   use_cache=True, # default is True\n",
    "                   logits_processor=[grammar_processor])\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "poem = generate_alliterative_poem_v2(\"donkey\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11412660-ac2e-4925-94d4-957f7bb715ea",
   "metadata": {},
   "source": [
    "Result:\n",
    "```\n",
    "Little donkey, ears so bright,\n",
    "Hee-hawing loud through day's delight,\n",
    "He trots along with gentle pace,\n",
    "A friendly friend in a sunny place.\n",
    "```\n",
    "Has 3 ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda481a-3c45-4a0f-b637-524c11a6c792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
