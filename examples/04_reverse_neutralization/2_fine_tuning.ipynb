{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Neutralization Example to generate a dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet  openai python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "load_dotenv(\"../saved_keys.env\")\n",
    "\n",
    "assert os.environ[\"OPENAI_API_KEY\"][:2] == \"sk\",\\\n",
    "       \"Please sign up for access to the OpenAI API and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the collection of emails\n",
    "emails = []\n",
    "with open(\"hawaiian_emails.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        emails.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee217c397174d5d8c00a9ee6fa950cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Neutralize the emails\n",
    "\n",
    "prompt = \"\"\"\n",
    "Neutralize the tone and style from the following email to make it professional and suitable for communication between executives who may not know each other very well.\n",
    "\n",
    "{email}\n",
    "\"\"\"\n",
    "\n",
    "neutralized_emails = []\n",
    "\n",
    "for email in tqdm(emails):\n",
    "    prompt_with_email = prompt.format(email=email)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_with_email}]\n",
    "    )\n",
    "\n",
    "    neutralized_emails.append(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for email, neutralized_email in zip(emails, neutralized_emails):\n",
    "    dataset.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "            {\"role\": \"user\", \"content\": neutralized_email},\n",
    "            {\"role\": \"assistant\", \"content\": email}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# write out the dataset to a jsonl file\n",
    "with open(\"dataset.jsonl\", \"w\") as f:\n",
    "    for item in dataset:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutralized email: Subject: Summary of Marketing Team Meeting - {date}\n",
      "\n",
      "Dear Marketing team,\n",
      "\n",
      "I trust this email finds you well. I wanted to provide a brief summary of our recent team meeting held on {date} at {time} in {location}.\n",
      "\n",
      "In our discussions regarding the Q2 roadmap, we came to agreements on:\n",
      "- Prioritizing key objectives for the upcoming quarter\n",
      "- Identifying challenges and exploring potential solutions\n",
      "- Updating the timeline and outlining deliverables\n",
      "\n",
      "Moving forward, we plan to:\n",
      "- Arrange a follow-up meeting for next week\n",
      "- Request that all updated documentation be shared by Friday\n",
      "\n",
      "Should you have any queries or if any crucial points were omitted, please do not hesitate to reach out.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Evelyn\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Personalized email: Subject: Aloha from the Marketing Team Meeting Summary - {date}\n",
      "\n",
      "Body: Aloha Marketing team,\n",
      "\n",
      "I hope this email finds you all in good spirits. I'm writing to give a summary of our team meeting that took place on {date} at {time} in {location}.\n",
      "\n",
      "During our discussion about the Q2 roadmap, we covered several key points:\n",
      "- We aligned on priorities for the next quarter\n",
      "- We talked about challenges and potential solutions\n",
      "- We updated the timeline and deliverables\n",
      "\n",
      "Next steps:\n",
      "- Letâ€™s schedule a follow-up meeting for next week\n",
      "- Please share the updated documentation by Friday\n",
      "\n",
      "If you have any questions or if I missed anything important, please let me know.\n",
      "\n",
      "Best wishes,\n",
      "Evelyn\n"
     ]
    }
   ],
   "source": [
    "# show comparison the neutralized email and the personalized email, limit example to 1\n",
    "\n",
    "print(f\"Neutralized email: {neutralized_emails[0]}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Personalized email: {emails[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current files in OpenAI:\n",
      "  - file-FcXPJovX8KHTQiEmNN3sen: 9797739828e95409.jsonl (fine-tune) - processed\n",
      "  - file-XIoQr4yA8PiaZ7rLbzO3pgdx: parties.csv (assistants) - processed\n",
      "  - file-MshL6yZB8ORDEct3iH19mKyu: global-parties.json (assistants) - processed\n",
      "  - file-RRK6DEb4oAnAqFf4PLXAAUPm: compiled_results.csv (fine-tune-results) - processed\n",
      "  - file-YDeBQK0v4BRWMzQiIsxvHSLi: compiled_results.csv (fine-tune-results) - processed\n",
      "Total files: 31\n",
      "Local dataset.jsonl exists - Size: 257313 bytes\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check current files before upload\n",
    "print(\"Current files in OpenAI:\")\n",
    "try:\n",
    "    files = client.files.list()\n",
    "    for file in files.data[:5]:  # Show first 5 files\n",
    "        print(f\"  - {file.id}: {file.filename} ({file.purpose}) - {file.status}\")\n",
    "    print(f\"Total files: {len(files.data)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing files: {e}\")\n",
    "\n",
    "# Also check if dataset.jsonl exists locally\n",
    "import os\n",
    "if os.path.exists(\"dataset.jsonl\"):\n",
    "    file_size = os.path.getsize(\"dataset.jsonl\")\n",
    "    print(f\"Local dataset.jsonl exists - Size: {file_size} bytes\")\n",
    "else:\n",
    "    print(\"ERROR: dataset.jsonl not found locally!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The model is able to handle the task, but it fails on the correct placeholder tags or isn't hitting the correct tone you prefer. Let's fix those issues by fine-tuning a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully!\n",
      "File ID: file-Fz9PnC3tqdYjQrHG57tER8\n",
      "File status: processed\n",
      "File bytes: 257313\n",
      "File purpose: fine-tune\n",
      "File exists in OpenAI: True\n"
     ]
    }
   ],
   "source": [
    "# Upload the training file\n",
    "training_file = client.files.create(\n",
    "    file=open(\"dataset.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Print the file info to confirm upload was successful\n",
    "print(f\"File uploaded successfully!\")\n",
    "print(f\"File ID: {training_file.id}\")\n",
    "print(f\"File status: {training_file.status}\")\n",
    "print(f\"File bytes: {training_file.bytes}\")\n",
    "print(f\"File purpose: {training_file.purpose}\")\n",
    "\n",
    "# Wait a moment for the file to be processed\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "# Verify the file exists by listing files\n",
    "files = client.files.list()\n",
    "uploaded_file_exists = any(file.id == training_file.id for file in files.data)\n",
    "print(f\"File exists in OpenAI: {uploaded_file_exists}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo\"  # Base model to fine-tune\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: validating_files\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: succeeded\n",
      "Fine-tuning complete! You can now use model: ft:gpt-3.5-turbo-0125:digits::BqTY2RHl\n"
     ]
    }
   ],
   "source": [
    "# Continuously check the status of the fine-tuning job\n",
    "while True:\n",
    "    job_status = client.fine_tuning.jobs.retrieve(job.id)\n",
    "    print(f\"Job status: {job_status.status}\")\n",
    "\n",
    "    if job_status.status in ['succeeded', 'failed']:\n",
    "        break\n",
    "\n",
    "    print(\"Waiting 120 seconds...\")\n",
    "    time.sleep(120)\n",
    "\n",
    "if job_status.status == 'succeeded':\n",
    "    print(f\"Fine-tuning complete! You can now use model: {job_status.fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"Fine-tuning failed. Check the job status for more information.\")\n",
    "\n",
    "# Once the job is complete, you can use the fine-tuned model\n",
    "# The fine-tuned model ID will be available in job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Feedback on mobile app\n",
      "\n",
      "Body: Aloha {name},\n",
      "\n",
      "Mahalo for sharing the mobile app with me. I've reviewed it and would like to provide some constructive feedback.\n",
      "\n",
      "Here are my main observations:\n",
      "- Reviewed current progress and milestones\n",
      "- Aligned on priorities for the next quarter\n",
      "- Discussed challenges and potential solutions\n",
      "\n",
      "I believe implementing these suggestions would further strengthen the mobile app. Please let me know if you'd like to talk about any of these points in more detail.\n",
      "\n",
      "Warm aloha,  \n",
      "{name}\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email with neutralized_emails[0]\n",
    "# Generally it is ad practise to test the model with a sample input from the training data,\n",
    "# but we want to check the output of the fine-tuned model.\n",
    "\n",
    "# Test the fine-tuned model with a sample input neutralized_emails[0]\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": neutralized_emails[20]},]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Request for project timeline update\n",
      "\n",
      "Body: Aloha Sam,\n",
      "\n",
      "I hope youâ€™re doing well. Iâ€™m reaching out because I need an update on the project timeline.\n",
      "\n",
      "Could you please share this with me by the end of the day? Itâ€™s needed for our next steps.\n",
      "\n",
      "Mahalo in advance for your help.\n",
      "\n",
      "Best,  \n",
      "Alex\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email\n",
    "\n",
    "test_email = \"\"\"\n",
    "Subject: Request for Project Timeline Update\n",
    "\n",
    "Body: Hi Sam,\n",
    "\n",
    "I am writing to request an update on the project timeline. Please provide the update by the end of the day, as it is important for our upcoming steps.\n",
    "\n",
    "Thank you.\n",
    "\n",
    "Best,\n",
    "Alex\n",
    "\"\"\"\n",
    "\n",
    "# Test the fine-tuned model with a sample input\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": test_email}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Invitation to Present on 2026 FIFA World Cup Marketing Campaign\n",
      "\n",
      "Dear Gretl,\n",
      "\n",
      "I hope this email finds you well. I am writing to invite you to give a presentation on the marketing campaign surrounding the 2026 FIFA World Cup. Your expertise and insight would greatly benefit our team in understanding the strategies and efforts being implemented for this prestigious event.\n",
      "\n",
      "We believe that your presentation will be instrumental in providing valuable information and inspiration as we work towards our own marketing objectives.\n",
      "\n",
      "Please let me know your availability and preferred dates for the presentation. We are flexible and will accommodate your schedule accordingly.\n",
      "\n",
      "Thank you in advance for considering this invitation. We are looking forward to hearing from you soon.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Title]\n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a short email to Gretl inviting her to give a presentation on the marketing campaign around the 2026 FIFA World Cup.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant writing letters suitable for communication between executives.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "neutral_email = response.choices[0].message.content\n",
    "\n",
    "print(neutral_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Aloha and invitation to present on 2026 FIFA World Cup marketing campaign\n",
      "\n",
      "Body: Aloha Gretl,\n",
      "\n",
      "I hope this email finds you in good spirits. Iâ€™m reaching out because Iâ€™d love for you to share your manaâ€˜o on the marketing campaign for the 2026 FIFA World Cup.\n",
      "\n",
      "I believe your perspective would be incredibly valuable for our team, helping us gain a better understanding of the strategies and initiatives in place for this exciting event.\n",
      "\n",
      "Iâ€™m sure your presentation would be both insightful and inspiring, and would help us further our own marketing efforts.\n",
      "\n",
      "Could you please let me know your availability to present? Iâ€™m flexible and can work around your schedule.\n",
      "\n",
      "Mahalo in advance for considering my request. Iâ€™m really looking forward to hearing from you.\n",
      "\n",
      "Warmest aloha,  \n",
      "[Your Name]  \n",
      "[Your Title]  \n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": neutral_email}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
