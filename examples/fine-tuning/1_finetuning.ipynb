{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "load_dotenv(\"../saved_keys.env\")\n",
    "\n",
    "assert os.environ[\"OPENAI_API_KEY\"][:2] == \"sk\",\\\n",
    "       \"Please sign up for access to the OpenAI API and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data, you can create the training data with the generate_fine_tuning_dataset.py script\n",
    "with open(\"training_data.jsonl\", \"r\") as f:\n",
    "    training_data = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'role': 'system', 'content': 'You are a helpful assistant converting notes to professional emails.'}, {'role': 'user', 'content': 'urgent: need meeting minutes by {deadline}\\nfor stakeholder presentaton\\ndetails:\\n- This is needed for our upcoming presentation to stakeholders.\\n- will need ur help asap\\n- send 2 me when rdy Style: request'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: Subject: Request for Meeting Minutes by {Deadline} for Stakeholder Presentation\n",
      "\n",
      "Dear [Recipient],\n",
      "\n",
      "I hope this message finds you well. I am reaching out to request your urgent assistance in preparing meeting minutes for our recent meeting, which are required for our upcoming stakeholder presentation.\n",
      "\n",
      "The meeting minutes are crucial for ensuring that we accurately represent the discussions and decisions made during the meeting to our stakeholders. Your prompt attention to this matter is greatly appreciated. \n",
      "\n",
      "Please send the completed meeting minutes to me as soon as they are ready. If you have any questions or need further information, please do not hesitate to reach out to me.\n",
      "\n",
      "Thank you in advance for your prompt action on this request.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# Let's infer the first sample\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=training_data[0][\"messages\"][:2]\n",
    ")\n",
    "print(f\"Input: {training_data[0]['messages'][:2]}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Output: {response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The model is able to handle the task, but it fails on the correct placeholder tags or isn't hitting the correct tone you prefer. Let's fix those issues by fine-tuning a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "training_file = client.files.create(\n",
    "    file=open(\"training_data.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: validating_files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo\"  # Base model to fine-tune\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: running\n",
      "Waiting 10 seconds...\n",
      "Job status: succeeded\n",
      "Fine-tuning complete! You can now use model: ft:gpt-3.5-turbo-0125:digits::AwfkmZb9\n"
     ]
    }
   ],
   "source": [
    "# Continuously check the status of the fine-tuning job\n",
    "while True:\n",
    "    job_status = client.fine_tuning.jobs.retrieve(job.id)\n",
    "    print(f\"Job status: {job_status.status}\")\n",
    "\n",
    "    if job_status.status in ['succeeded', 'failed']:\n",
    "        break\n",
    "\n",
    "    print(\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)\n",
    "\n",
    "if job_status.status == 'succeeded':\n",
    "    print(f\"Fine-tuning complete! You can now use model: {job_status.fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"Fine-tuning failed. Check the job status for more information.\")\n",
    "\n",
    "# Once the job is complete, you can use the fine-tuned model\n",
    "# The fine-tuned model ID will be available in job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated email:\n",
      "Subject: Request for meeting minutes\n",
      "\n",
      "Body: Hi {name},\n",
      "\n",
      "I hope you're doing well. I'm reaching out because I need meeting minutes by {deadline}.\n",
      "\n",
      "This is needed for our upcoming presentation to stakeholders.\n",
      "\n",
      "Could you please help me with this? Let me know if you need any additional information.\n",
      "\n",
      "Thank you in advance for your help.\n",
      "\n",
      "Best,\n",
      "{name}\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email with training_data[0]['messages']\n",
    "# Generally it is ad practise to test the model with a sample input from the training data,\n",
    "# but we want to check the different outputs between the generic gpt-3.5-turbo and the fine-tuned model.\n",
    "\n",
    "# Test the fine-tuned model with a sample input training_data[0]['messages']\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=training_data[0]['messages'][:2]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated email:\n",
      "Subject: Request for meeting\n",
      "\n",
      "Body: Dear John,\n",
      "\n",
      "I hope you're doing well. I'm reaching out because I'd like to discuss Q4 planning with you.\n",
      "\n",
      "Please let me know when you're available to meet.\n",
      "\n",
      "Thank you,\n",
      "{name}\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email\n",
    "\n",
    "# Test the fine-tuned model with a sample input\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting notes to professional emails.\"},\n",
    "        {\"role\": \"user\", \"content\": \"schedule a meeting with John about the Q4 planning\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated email:\")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
