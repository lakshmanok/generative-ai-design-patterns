{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62246b6b-17c0-4387-b27c-8a435e7b93d5",
   "metadata": {},
   "source": [
    "## Using Direct Preference Optimization on a preference dataset\n",
    "\n",
    "Hardware requirements:  Requires L4 GPU and 8 vCPUs with 32 GB for Qwen\n",
    "\n",
    "For Llama 3.2-3B, this is not enough because the L4 has only 21GB of RAM (rule of thumb is that you need 8x parameter size for DPO, so 24GB for this model). Need to try A100 or distributing over multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c3366b-dd37-4526-aeb7-7cfc7a7b92ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install --quiet transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e407f98-cc34-44f7-952c-96b1c0f83ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# has to match generate_synthetic_data so that data is in-distribution\n",
    "# MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "MODEL_ID = \"Qwen/Qwen2-0.5B-Instruct\"   \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "assert os.environ[\"HF_TOKEN\"][:2] == \"hf\",\\\n",
    "       \"Please sign up for access to the specific Llama model via HuggingFace and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c55dd0d-3df9-43ad-aa88-bd2776265b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278f09a59c4043c094b7fa7232cd0b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "train_dataset = load_dataset('json', data_files=\"ad_preference_dataset.jsonl\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f330a81-16c4-402b-babe-25db0b24ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, device_map=\"auto\", low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ce0421-1cd1-4333-8340-b61682c5ba2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'llama' in MODEL_ID:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aab82da-ce2e-41a1-b405-8ccd2e0b5648",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363903361d50472fb5ba81326f325887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f281b4fa10ae4c459dddb0fa8393f0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29f448035e94fcf8484c2386e74689e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 03:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.591000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.659700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.232900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.788200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.065400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.320500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.328600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.159700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.35067893626672836, metrics={'train_runtime': 191.5221, 'train_samples_per_second': 1.566, 'train_steps_per_second': 1.566, 'total_flos': 0.0, 'train_loss': 0.35067893626672836, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = DPOConfig(output_dir=\"ClassifiedAds-DPO\", logging_steps=10, \n",
    "                          per_device_train_batch_size=1,\n",
    "                          per_device_eval_batch_size=1\n",
    "                         )\n",
    "trainer = DPOTrainer(model=model, args=training_args, processing_class=tokenizer, train_dataset=train_dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacba1dd-f9e4-4f89-a434-9b87812e3edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc110254-aa2f-46c5-a927-71866c91bd71",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try out the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79e7bd4-d78a-4e8b-a97d-b09169a96fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=\"ClassifiedAds-DPO\",\n",
    "    use_fast=True,\n",
    "    kwargs={\n",
    "        \"return_full_text\": False,\n",
    "    },\n",
    "    model_kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09d9ede-96a7-4228-a7de-3d2b7dacaf77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ad: \"Pachinko, the classic tale of a man\\'s obsession with gambling and his love for a woman he meets while playing a pachinko game. A rare edition priced at $5. For more information or to arrange pickup, please contact [Your Name] at [Your Phone Number]. Thank you!\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYSTEM_PROMPT=f\"\"\"\n",
    "            You are a resident who is listing a used item for sale on a neighborhood online group.\n",
    "            An ad for used items in this neighborhood group is 1-3 sentences. \n",
    "\"\"\"\n",
    "def create_classified_ad(item: str, price: str) -> str:\n",
    "    system_prompt = SYSTEM_PROMPT\n",
    "    user_prompt = f\"\"\"\n",
    "        Write an ad to sell a {item} priced at {price}\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256,\n",
    "                   pad_token_id=pipe.tokenizer.eos_token_id\n",
    "                  )\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "create_classified_ad(\"book Pachinko by Min Jin Lee\", \"$5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ff8bf-c480-422e-ad35-64f2e5a0e284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
