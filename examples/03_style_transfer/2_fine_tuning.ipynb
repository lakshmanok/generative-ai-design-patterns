{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine - Tuning a model to generate professional emails from notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet  openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "load_dotenv(\"../keys.env\")\n",
    "\n",
    "assert os.environ[\"OPENAI_API_KEY\"][:2] == \"sk\",\\\n",
    "       \"Please sign up for access to the OpenAI API and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data, you can create the training data with the generate_fine_tuning_dataset.py script\n",
    "with open(\"fine_tuning_dataset.jsonl\", \"r\") as f:\n",
    "    training_data = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [{'role': 'system', 'content': 'You are a helpful assistant converting notes to professional emails.'}, {'role': 'user', 'content': 'feedback 4 mobile app\\nlooked @ everything, here r my thots:\\nReviewed current progress and milestones\\nAligned on priorities for the next quarter\\nDiscussed challenges and potential solutions\\nlets discuss if needed'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output: Subject: Feedback and Next Steps for Mobile App Development\n",
      "\n",
      "Dear Team,\n",
      "\n",
      "I hope this message finds you well. I have thoroughly reviewed our current progress and milestones for the mobile app development project and wanted to share my thoughts with you.\n",
      "\n",
      "During our recent meeting, we had a productive discussion where we:\n",
      "\n",
      "1. Reviewed the progress made so far and identified key milestones achieved.\n",
      "2. Aligned on priorities for the upcoming quarter, ensuring clarity on our focus areas.\n",
      "3. Discussed the challenges we are currently facing and brainstormed potential solutions to address them.\n",
      "\n",
      "I believe we are on the right track, and I appreciate everyone's dedication and hard work towards the success of this project. Should further discussions be required on any of the points mentioned above, I am open to scheduling a meeting to delve deeper into these matters.\n",
      "\n",
      "Thank you for your continued commitment and collaboration. Let's keep up the momentum and work towards our project goals.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Position]\n"
     ]
    }
   ],
   "source": [
    "# Let's infer the first sample\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=training_data[0][\"messages\"][:2]\n",
    ")\n",
    "print(f\"Input: {training_data[0]['messages'][:2]}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Output: {response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The model is able to handle the task, but it fails on the correct placeholder tags or isn't hitting the correct tone you prefer. Let's fix those issues by fine-tuning a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "training_file = client.files.create(\n",
    "    file=open(\"fine_tuning_dataset.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo\"  # Base model to fine-tune\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: validating_files\n",
      "Waiting 60 seconds...\n",
      "Job status: validating_files\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: running\n",
      "Waiting 60 seconds...\n",
      "Job status: succeeded\n",
      "Fine-tuning complete! You can now use model: ft:gpt-3.5-turbo-0125:digits::B7waeTJO\n"
     ]
    }
   ],
   "source": [
    "# Continuously check the status of the fine-tuning job\n",
    "while True:\n",
    "    job_status = client.fine_tuning.jobs.retrieve(job.id)\n",
    "    print(f\"Job status: {job_status.status}\")\n",
    "\n",
    "    if job_status.status in ['succeeded', 'failed']:\n",
    "        break\n",
    "\n",
    "    print(\"Waiting 60 seconds...\")\n",
    "    time.sleep(60)\n",
    "\n",
    "if job_status.status == 'succeeded':\n",
    "    print(f\"Fine-tuning complete! You can now use model: {job_status.fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"Fine-tuning failed. Check the job status for more information.\")\n",
    "\n",
    "# Once the job is complete, you can use the fine-tuned model\n",
    "# The fine-tuned model ID will be available in job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated email:\n",
      "Subject: Feedback on mobile app\n",
      "\n",
      "Body: Hello {name},\n",
      "\n",
      "Thank you for sharing mobile app with me. I've reviewed it and would like to provide some constructive feedback.\n",
      "\n",
      "Here are my main observations:\n",
      "- Reviewed current progress and milestones\n",
      "- Aligned on priorities for the next quarter\n",
      "- Discussed challenges and potential solutions\n",
      "\n",
      "I believe implementing these suggestions would further strengthen the mobile app. Please let me know if you'd like to discuss any of these points in more detail.\n",
      "\n",
      "Kind regards,\n",
      "{name}\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email with training_data[0]['messages']\n",
    "# Generally it is ad practise to test the model with a sample input from the training data,\n",
    "# but we want to check the different outputs between the generic gpt-3.5-turbo and the fine-tuned model.\n",
    "\n",
    "# Test the fine-tuned model with a sample input training_data[0]['messages']\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=training_data[0]['messages'][:2]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated email:\n",
      "Subject: Request for meeting\n",
      "\n",
      "Body: Hi John,\n",
      "\n",
      "I hope you're doing well. I'm reaching out because I'd like to discuss Q4 planning with you.\n",
      "\n",
      "Could we please you set up a time to meet?\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email\n",
    "\n",
    "# Test the fine-tuned model with a sample input\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting notes to professional emails.\"},\n",
    "        {\"role\": \"user\", \"content\": \"schedule a meeting with John about the Q4 planning\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated email:\")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
