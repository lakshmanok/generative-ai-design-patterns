{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f4b00e-59c2-4496-a0e5-cd10dff0f0eb",
   "metadata": {},
   "source": [
    "## Changing logits based on desired alliteration\n",
    "\n",
    "We want to generate a poem where as many words as possible start with a desired letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41664a72-3e67-4e57-9e6d-2a01ed7ed8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade --quiet transformers torch fbgemm-gpu accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b078983c-cda3-46d0-8438-d284bc017b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CHANGE this to the Llama model for which you have applied for access via Hugging Face\n",
    "# See: https://www.llama.com/docs/getting-the-models/hugging-face/\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "assert os.environ[\"HF_TOKEN\"][:2] == \"hf\",\\\n",
    "       \"Please sign up for access to the specific Llama model via HuggingFace and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7717ded-01ba-4fa2-b1c4-44b342cc0ab6",
   "metadata": {},
   "source": [
    "## Zero-shot generation\n",
    "\n",
    "Without any logits processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cad70f-b88b-4b35-98fd-d9be4b64f268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ded9840a88744249f04a7e1b34f0a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=MODEL_ID,\n",
    "    use_fast=True,\n",
    "    kwargs={\n",
    "        \"return_full_text\": False,\n",
    "    },\n",
    "    model_kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b573da4-bf5e-4853-b5de-8d7e80fa4337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hee-haw, the donkey sings,\n",
      "A loud voice that joyfully brings,\n",
      "A smile to the heart of a child.\n"
     ]
    }
   ],
   "source": [
    "def generate_poem(animal: str) -> str:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are writing nursery rhymes about animals for a children's book.\n",
    "        Each poem should be 3-5 lines long.\n",
    "        Return only the poem, without any introduction or preamble.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "        Write a poem about a {animal}.\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256)\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "poem = generate_poem(\"donkey\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfecc3-55c7-4059-94bc-eae29d982cab",
   "metadata": {},
   "source": [
    "Result:\n",
    "```\n",
    "Hee-haw, a donkey so bright,\n",
    "Carrying loads with all his might,\n",
    "His soft fur and gentle eyes shine,\n",
    "A friendly friend, always on my mind.\n",
    "```\n",
    "Well shine & mind is not the perfect rhyme,\n",
    "but still pretty good ... but if we ask for the poem about donkeys to\n",
    "also be alliterative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d864a57-d022-4783-884e-dacd778be4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dainty donkeys dance down dusty roads,\n",
      "Delightful droplets dripping from their noses' folds.\n",
      "Doting dads delight in their darling donkey's doze.\n"
     ]
    }
   ],
   "source": [
    "def generate_alliterative_poem(animal: str) -> str:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are writing alliterative nursery rhymes about animals for a children's book.\n",
    "        Each poem should be 3-5 lines long.\n",
    "        Return only the poem, without any introduction or preamble.\n",
    "    \"\"\"\n",
    "    \n",
    "    # alliterate on the first letter of the animal. So, donkey would be D\n",
    "    user_prompt = f\"\"\"\n",
    "        Write a poem about a {animal} that contains alliterations involving the letter {animal.upper()[0]}\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256)\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "poem = generate_alliterative_poem(\"donkey\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d68ad3-28df-4a1b-9d77-a4dea150c2a3",
   "metadata": {},
   "source": [
    "Result:\n",
    "```\n",
    "Dainty donkeys dance down dusty roads,\n",
    "Delightful droplets dripping from their noses' folds.\n",
    "Doting dads delight in their darling donkey's doze.\n",
    "```\n",
    "The poem above is not great. By trying to match the style, the quality has gone way down.\n",
    "Does a donkey with snot dripping from its nostrils delightful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d262c-edd8-40e7-8441-9cfc8f8dd1f7",
   "metadata": {},
   "source": [
    "## Use logits processing to enhance the alliteration\n",
    "\n",
    "We'll use the poem prompt, but use logits processing to prefer words that start with the desired letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddad926f-2822-47ea-88c5-db42c8316e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers.generation.logits_process import (\n",
    "    LogitsProcessor,\n",
    "    LOGITS_PROCESSOR_INPUTS_DOCSTRING,\n",
    ")\n",
    "from transformers.utils import add_start_docstrings\n",
    "\n",
    "class AlliterativeLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, tokenizer, start_letter):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.start_letter = start_letter\n",
    "      \n",
    "    @add_start_docstrings(LOGITS_PROCESSOR_INPUTS_DOCSTRING)\n",
    "    def __call__(\n",
    "        self, input_ids: torch.LongTensor, input_logits: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        output_logits = input_logits.clone()\n",
    "            \n",
    "        num_matches = [0] * len(input_ids)\n",
    "        for idx, seq in enumerate(input_ids):\n",
    "            # decode the sequence\n",
    "            decoded = self.tokenizer.decode(seq)\n",
    "            # count the number of words that start with desired letter\n",
    "            num_matches[idx] = np.sum([1 for word in decoded.split() if word[0] == self.start_letter])\n",
    "        max_matches = np.max(num_matches)\n",
    "          \n",
    "        # logits goes from -inf to zero.  Mask out the non-max sequences; torch doesn't like it to be -np.inf\n",
    "        for idx in range(len(input_ids)):\n",
    "            if num_matches[idx] != max_matches:\n",
    "                output_logits[idx] = -10000\n",
    "                  \n",
    "        return output_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef0ee7d-e7f9-4354-b511-958d53a7ecf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Little donkey, ears so bright,\n",
      "Hee-hawing loud through day's delight,\n",
      "He trots along with gentle pace,\n",
      "A friendly friend in a sunny place.\n"
     ]
    }
   ],
   "source": [
    "def generate_alliterative_poem_v2(animal: str) -> str:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are writing nursery rhymes about animals for a children's book.\n",
    "        Each poem should be 3-5 lines long.\n",
    "        Return only the poem, without any introduction or preamble.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "        Write a poem about a {animal}.\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    # alliterate on the first letter of the animal. So, donkey would be D\n",
    "    grammar_processor = AlliterativeLogitsProcessor(pipe.tokenizer, animal[0])\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256,\n",
    "                   do_sample=True,\n",
    "                   temperature=0.8,\n",
    "                   num_beams=10,\n",
    "                   use_cache=True, # default is True\n",
    "                   logits_processor=[grammar_processor])\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "poem = generate_alliterative_poem_v2(\"donkey\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11412660-ac2e-4925-94d4-957f7bb715ea",
   "metadata": {},
   "source": [
    "Result:\n",
    "```\n",
    "Little donkey, ears so bright,\n",
    "Hee-hawing loud through day's delight,\n",
    "He trots along with gentle pace,\n",
    "A friendly friend in a sunny place.\n",
    "```\n",
    "Has 3 ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f8396-d5e7-4e2f-b896-c5d4a30b1439",
   "metadata": {},
   "source": [
    "## Combine prompting and sequence selection\n",
    "\n",
    "Enhance the prompt but make it clear we want it to be readable,\n",
    "but use logits processing to prefer words that start with the desired letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "586183fd-5b2b-4d6c-a8f2-13641b0cdf37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down the dusty desert, donkey did stray\n",
      "Dreaming of delicious dates to devour each day\n",
      "Dainty donkey danced down the desert way\n"
     ]
    }
   ],
   "source": [
    "def generate_alliterative_poem_v3(animal: str) -> str:\n",
    "    start_letter = animal[0]\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "        You are writing nursery rhymes about animals for a children's book.\n",
    "        Each poem should be 3-5 lines long. The poem must be readable and suitable for children.\n",
    "        Return only the poem, without any introduction or preamble.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "        Write a poem about a {animal} that has a few alliterations involving {start_letter}.\n",
    "        Do not overdo alliteration, and emphasize readability.\n",
    "    \"\"\"\n",
    "\n",
    "    input_message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}   \n",
    "    ]\n",
    "    \n",
    "    # alliterate on the first letter of the animal. So, donkey would be D\n",
    "    grammar_processor = AlliterativeLogitsProcessor(pipe.tokenizer, start_letter)\n",
    "    \n",
    "    results = pipe(input_message, \n",
    "                   max_new_tokens=256,\n",
    "                   do_sample=True,\n",
    "                   temperature=0.8,\n",
    "                   num_beams=10,\n",
    "                   use_cache=True, # default is True\n",
    "                   logits_processor=[grammar_processor])\n",
    "    return results[0]['generated_text'][-1]['content'].strip()\n",
    "\n",
    "poem = generate_alliterative_poem_v3(\"donkey\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ce7c1-bff2-4186-98d0-8b014f66c854",
   "metadata": {},
   "source": [
    "Result:\n",
    "```\n",
    "Down the dusty desert, donkey did stray\n",
    "Dreaming of delicious dates to devour each day\n",
    "Dainty donkey danced down the desert way\n",
    "```\n",
    "It's still a readable poem, but we have picked the one with the most ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58154506-ff85-41dc-a436-6364283b9a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
