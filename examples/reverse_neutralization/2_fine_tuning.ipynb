{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Neutralization Example to generate a dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet  openai python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "load_dotenv(\"../keys.env\")\n",
    "\n",
    "assert os.environ[\"OPENAI_API_KEY\"][:2] == \"sk\",\\\n",
    "       \"Please sign up for access to the OpenAI API and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the collection of emails\n",
    "emails = []\n",
    "with open(\"emails.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        emails.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e123a64dfeb64f81965f977b1b226a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Neutralize the emails\n",
    "\n",
    "prompt = \"\"\"\n",
    "Neutralize the tone and style from the following email to make it professional and suitable for communication between executives who may not know each other very well.\n",
    "\n",
    "{email}\n",
    "\"\"\"\n",
    "\n",
    "neutralized_emails = []\n",
    "\n",
    "for email in tqdm(emails):\n",
    "    prompt_with_email = prompt.format(email=email)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_with_email}]\n",
    "    )\n",
    "\n",
    "    neutralized_emails.append(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for email, neutralized_email in zip(emails, neutralized_emails):\n",
    "    dataset.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "            {\"role\": \"user\", \"content\": neutralized_email},\n",
    "            {\"role\": \"assistant\", \"content\": email}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# write out the dataset to a jsonl file\n",
    "with open(\"dataset.jsonl\", \"w\") as f:\n",
    "    for item in dataset:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutralized email: Subject: Summary of Marketing Team Meeting - {date}\n",
      "\n",
      "Dear Marketing team,\n",
      "\n",
      "I trust this email finds you well. I would like to update you on the meeting we had on {date} at {time} in {location}.\n",
      "\n",
      "In our discussion regarding the Q2 roadmap, we addressed the following points:\n",
      "- Agreed on priorities for the upcoming quarter\n",
      "- Delved into challenges and potential solutions\n",
      "- Revised the timeline and deliverables\n",
      "\n",
      "Our proposed next steps are as follows:\n",
      "- Arrange a follow-up meeting next week\n",
      "- Distribute updated documentation by Friday\n",
      "\n",
      "Should you have any queries or if there are any key points I may have overlooked, please don't hesitate to reach out.\n",
      "\n",
      "Best regards,\n",
      "{name}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Personalized email: Subject: Marketing Team Meeting Summary - {date}\n",
      "\n",
      "Body: Dear Marketing team,\n",
      "\n",
      "I hope this email finds you well. I'm writing to summarize our team meeting that took place on {date} at {time} in {location}.\n",
      "\n",
      "During our discussion about Q2 roadmap, we covered several key points:\n",
      "- Aligned on priorities for the next quarter\n",
      "- Discussed challenges and potential solutions\n",
      "- Updated timeline and deliverables\n",
      "\n",
      "Next steps:\n",
      "- Schedule follow-up meeting next week\n",
      "- Share updated documentation by Friday\n",
      "\n",
      "Please let me know if you have any questions or if I missed anything important.\n",
      "\n",
      "Best regards,\n",
      "{name}\n"
     ]
    }
   ],
   "source": [
    "# show comparison the neutralized email and the personalized email, limit example to 1\n",
    "\n",
    "print(f\"Neutralized email: {neutralized_emails[0]}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Personalized email: {emails[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The model is able to handle the task, but it fails on the correct placeholder tags or isn't hitting the correct tone you prefer. Let's fix those issues by fine-tuning a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "training_file = client.files.create(\n",
    "    file=open(\"dataset.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo\"  # Base model to fine-tune\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: validating_files\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: succeeded\n",
      "Fine-tuning complete! You can now use model: ft:gpt-3.5-turbo-0125:digits::B7ymWyNI\n"
     ]
    }
   ],
   "source": [
    "# Continuously check the status of the fine-tuning job\n",
    "while True:\n",
    "    job_status = client.fine_tuning.jobs.retrieve(job.id)\n",
    "    print(f\"Job status: {job_status.status}\")\n",
    "\n",
    "    if job_status.status in ['succeeded', 'failed']:\n",
    "        break\n",
    "\n",
    "    print(\"Waiting 120 seconds...\")\n",
    "    time.sleep(120)\n",
    "\n",
    "if job_status.status == 'succeeded':\n",
    "    print(f\"Fine-tuning complete! You can now use model: {job_status.fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"Fine-tuning failed. Check the job status for more information.\")\n",
    "\n",
    "# Once the job is complete, you can use the fine-tuned model\n",
    "# The fine-tuned model ID will be available in job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated email:\n",
      "Subject: Marketing Team Meeting Summary - {date}\n",
      "\n",
      "Body: Dear Marketing team,\n",
      "\n",
      "I hope this email finds you well. I'm writing to summarize our team meeting that took place on {date} at {time} in {location}.\n",
      "\n",
      "During our discussion about Q2 roadmap, we covered several key points:\n",
      "- Aligned on priorities for the next quarter\n",
      "- Discussed challenges and potential solutions\n",
      "- Updated timeline and deliverables\n",
      "\n",
      "Next steps:\n",
      "- Schedule follow-up meeting next week\n",
      "- Share updated documentation by Friday\n",
      "\n",
      "Please let me know if you have any questions or if I missed anything important.\n",
      "\n",
      "Best regards,\n",
      "{name}\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email with neutralized_emails[0]\n",
    "# Generally it is ad practise to test the model with a sample input from the training data,\n",
    "# but we want to check the output of the fine-tuned model.\n",
    "\n",
    "# Test the fine-tuned model with a sample input neutralized_emails[0]\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": neutralized_emails[0]},]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Request for project timeline update\n",
      "\n",
      "Body: Hi {name},\n",
      "\n",
      "I hope you're doing well. I'm reaching out because I need project timeline updated.\n",
      "\n",
      "This is needed for our next steps by the end of the day.\n",
      "\n",
      "Could you please help me with this?\n",
      "\n",
      "Thank you,\n",
      "Alex\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email\n",
    "\n",
    "test_email = \"\"\"\n",
    "Subject: Request for Project Timeline Update\n",
    "\n",
    "Body: Hi Sam,\n",
    "\n",
    "I am writing to request an update on the project timeline. Please provide the update by the end of the day, as it is important for our upcoming steps.\n",
    "\n",
    "Thank you.\n",
    "\n",
    "Best,\n",
    "Alex\n",
    "\"\"\"\n",
    "\n",
    "# Test the fine-tuned model with a sample input\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": test_email}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Invitation to present on the 2026 FIFA World Cup marketing campaign\n",
      "\n",
      "Dear Gretl,\n",
      "\n",
      "I hope this message finds you well. I am reaching out to invite you to give a presentation on the marketing campaign surrounding the 2026 FIFA World Cup. Your expertise and valuable insights would be greatly appreciated by our team.\n",
      "\n",
      "The presentation will provide an opportunity for you to share your knowledge and expertise with our colleagues, and we believe that your input would significantly contribute to our understanding of successful marketing strategies for such a major global event.\n",
      "\n",
      "Please let me know if you are available and willing to present on this topic. We look forward to hearing from you and potentially collaborating on this project.\n",
      "\n",
      "Thank you for considering this invitation.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a short email to Gretl inviting her to give a presentation on the marketing campaign around the 2026 FIFA World Cup.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "neutral_email = response.choices[0].message.content\n",
    "\n",
    "print(neutral_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Invitation to present about FIFA World Cup 2026 marketing campaign\n",
      "\n",
      "Body: Hi {name},\n",
      "\n",
      "I hope you're doing well. I'm reaching out because I'd like to invite you to present about FIFA World Cup 2026 marketing campaign.\n",
      "\n",
      "I believe your insights would be incredibly valuable to our team. This is why I'd love to see you join us and share your knowledge.\n",
      "\n",
      "Please let me know if you're available to present. I'd love to discuss this in more detail.\n",
      "\n",
      "Kind regards,\n",
      "{name}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": neutral_email}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
