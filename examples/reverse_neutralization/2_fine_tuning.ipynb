{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Neutralization Example to generate a dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet  openai python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "load_dotenv(\"../keys.env\")\n",
    "\n",
    "assert os.environ[\"OPENAI_API_KEY\"][:2] == \"sk\",\\\n",
    "       \"Please sign up for access to the OpenAI API and provide access token in keys.env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the collection of emails\n",
    "emails = []\n",
    "with open(\"emails.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        emails.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1230a62f0b0c4f11b6c1c02dd33bc38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Neutralize the emails\n",
    "\n",
    "prompt = \"\"\"\n",
    "Neutralize the tone and style from the following email to make it professional and suitable for communication between executives who may not know each other very well.\n",
    "\n",
    "{email}\n",
    "\"\"\"\n",
    "\n",
    "neutralized_emails = []\n",
    "\n",
    "for email in tqdm(emails):\n",
    "    prompt_with_email = prompt.format(email=email)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_with_email}]\n",
    "    )\n",
    "\n",
    "    neutralized_emails.append(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for email, neutralized_email in zip(emails, neutralized_emails):\n",
    "    dataset.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "            {\"role\": \"user\", \"content\": neutralized_email},\n",
    "            {\"role\": \"assistant\", \"content\": email}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# write out the dataset to a jsonl file\n",
    "with open(\"dataset.jsonl\", \"w\") as f:\n",
    "    for item in dataset:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutralized email: Subject: Summary of Marketing Team Meeting - {date}\n",
      "\n",
      "Body: Good day Marketing team,\n",
      "\n",
      "I trust this message finds you well. I am reaching out to provide a recap of our recent team meeting held on {date} at {time} in {location}.\n",
      "\n",
      "During our discussion on the Q2 roadmap, we addressed the following key points:\n",
      "- Established alignment on priorities for the upcoming quarter\n",
      "- Explored and deliberated on challenges alongside potential resolutions\n",
      "- Revised the timeline and outlined deliverables\n",
      "\n",
      "Moving forward, our next actions will include:\n",
      "- Scheduling a follow-up meeting for next week\n",
      "- Distributing updated documentation by this Friday\n",
      "\n",
      "Should you have any inquiries or if I inadvertently overlooked any crucial details, please do not hesitate to reach out.\n",
      "\n",
      "Warm regards,\n",
      "Evelyn\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Personalized email: Subject: Marketing Team Meeting Summary - {date}\n",
      "\n",
      "Body: Dear Marketing team,\n",
      "\n",
      "I hope this email finds you well. I'm writing to summarize our team meeting that took place on {date} at {time} in {location}.\n",
      "\n",
      "During our discussion about Q2 roadmap, we covered several key points:\n",
      "- Aligned on priorities for the next quarter\n",
      "- Discussed challenges and potential solutions\n",
      "- Updated timeline and deliverables\n",
      "\n",
      "Next steps:\n",
      "- Schedule follow-up meeting next week\n",
      "- Share updated documentation by Friday\n",
      "\n",
      "Please let me know if you have any questions or if I missed anything important.\n",
      "\n",
      "Best regards,\n",
      "Evelyn\n"
     ]
    }
   ],
   "source": [
    "# show comparison the neutralized email and the personalized email, limit example to 1\n",
    "\n",
    "print(f\"Neutralized email: {neutralized_emails[0]}\")\n",
    "print(\"-\"*100)\n",
    "print(f\"Personalized email: {emails[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "The model is able to handle the task, but it fails on the correct placeholder tags or isn't hitting the correct tone you prefer. Let's fix those issues by fine-tuning a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training file\n",
    "training_file = client.files.create(\n",
    "    file=open(\"dataset.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo\"  # Base model to fine-tune\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: validating_files\n",
      "Waiting 120 seconds...\n",
      "Job status: queued\n",
      "Waiting 120 seconds...\n",
      "Job status: queued\n",
      "Waiting 120 seconds...\n",
      "Job status: queued\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: running\n",
      "Waiting 120 seconds...\n",
      "Job status: succeeded\n",
      "Fine-tuning complete! You can now use model: ft:gpt-3.5-turbo-0125:digits::B7zqBVSB\n"
     ]
    }
   ],
   "source": [
    "# Continuously check the status of the fine-tuning job\n",
    "while True:\n",
    "    job_status = client.fine_tuning.jobs.retrieve(job.id)\n",
    "    print(f\"Job status: {job_status.status}\")\n",
    "\n",
    "    if job_status.status in ['succeeded', 'failed']:\n",
    "        break\n",
    "\n",
    "    print(\"Waiting 120 seconds...\")\n",
    "    time.sleep(120)\n",
    "\n",
    "if job_status.status == 'succeeded':\n",
    "    print(f\"Fine-tuning complete! You can now use model: {job_status.fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"Fine-tuning failed. Check the job status for more information.\")\n",
    "\n",
    "# Once the job is complete, you can use the fine-tuned model\n",
    "# The fine-tuned model ID will be available in job_status.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Marketing Team Meeting Summary - {date}\n",
      "\n",
      "Body: Dear Marketing team,\n",
      "\n",
      "I hope this email finds you well. I'm writing to summarize our team meeting that took place on {date} at {time} in {location}.\n",
      "\n",
      "During our discussion about Q2 roadmap, we covered several key points:\n",
      "- Aligned on priorities for the next quarter\n",
      "- Discussed challenges and potential solutions\n",
      "- Updated timeline and deliverables\n",
      "\n",
      "Next steps:\n",
      "- Schedule follow-up meeting next week\n",
      "- Share updated documentation by Friday\n",
      "\n",
      "Please let me know if you have any questions or if I missed anything important.\n",
      "\n",
      "Best regards,\n",
      "Evelyn\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email with neutralized_emails[0]\n",
    "# Generally it is ad practise to test the model with a sample input from the training data,\n",
    "# but we want to check the output of the fine-tuned model.\n",
    "\n",
    "# Test the fine-tuned model with a sample input neutralized_emails[0]\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": neutralized_emails[0]},]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Request for project timeline update\n",
      "\n",
      "Body: Hi Sam,\n",
      "\n",
      "I hope you're doing well. I'm reaching out because I need project timeline.\n",
      "\n",
      "This is needed for our upcoming deliverables.\n",
      "\n",
      "Could you please help me with this? Let me know if you need any additional information.\n",
      "\n",
      "Thank you in advance for your help.\n",
      "\n",
      "Best,\n",
      "Alex\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the fine-tuned model to generate the email\n",
    "\n",
    "test_email = \"\"\"\n",
    "Subject: Request for Project Timeline Update\n",
    "\n",
    "Body: Hi Sam,\n",
    "\n",
    "I am writing to request an update on the project timeline. Please provide the update by the end of the day, as it is important for our upcoming steps.\n",
    "\n",
    "Thank you.\n",
    "\n",
    "Best,\n",
    "Alex\n",
    "\"\"\"\n",
    "\n",
    "# Test the fine-tuned model with a sample input\n",
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": test_email}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Invitation to Present on Marketing Campaign for 2026 FIFA World Cup\n",
      "\n",
      "Dear Gretl,\n",
      "\n",
      "I hope this message finds you well. I am writing to officially invite you to give a presentation on the marketing campaign surrounding the 2026 FIFA World Cup. Your expertise and insights would be invaluable to our team, and we are eager to hear your thoughts on this exciting project.\n",
      "\n",
      "We believe that your unique perspective and experience will bring a fresh and innovative approach to our marketing strategies for this upcoming event. Your presentation will provide valuable insights that will help guide our team in creating a successful campaign.\n",
      "\n",
      "Please let me know at your earliest convenience if you are available and willing to present. We are looking forward to hearing from you and are excited about the opportunity to collaborate on this important project.\n",
      "\n",
      "Thank you in advance for considering our invitation. We appreciate your time and expertise.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Title]\n",
      "[Company Name]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a short email to Gretl inviting her to give a presentation on the marketing campaign around the 2026 FIFA World Cup.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant writing letters suitable for communication between executives.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "neutral_email = response.choices[0].message.content\n",
    "\n",
    "print(neutral_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated personalized email:\n",
      "Subject: Invitation to present about marketing campaign for 2026 FIFA World Cup\n",
      "\n",
      "Body: Dear Gretl,\n",
      "\n",
      "I hope you're doing well. I'm reaching out because I'd like to invite you to present about marketing campaign for 2026 FIFA World Cup. I think your insights would be incredibly valuable in shaping our team's priorities and I'd love to discuss this opportunity with you in more detail.\n",
      "\n",
      "Please let me know if you're interested in discussing this further, or if you have any questions about what the presentation would entail.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=job_status.fine_tuned_model,  # Use the fine-tuned model\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant converting the neutralized email into personalized email.\"},\n",
    "        {\"role\": \"user\", \"content\": neutral_email}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated personalized email:\")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
